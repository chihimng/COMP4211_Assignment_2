{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAE from pretrained encoder\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "from tensorboardX import SummaryWriter\n",
    "from pa2_sample_code import get_datasets\n",
    "\n",
    "train_data, eval_data = get_datasets()\n",
    "\n",
    "# split train set into holdout_train and holdout_eval sets\n",
    "holdout_train_len = int(len(train_data) * 0.8)\n",
    "holdout_eval_len = len(train_data) - holdout_train_len\n",
    "holdout_train_data, holdout_eval_data = torch.utils.data.random_split(train_data, [holdout_train_len, holdout_eval_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaeFromPretrained(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CaeFromPretrained, self).__init__()\n",
    "        \n",
    "        self.encoder = torch.load('pretrained_encoder.pt')['model']\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=8, kernel_size=3, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=4, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=4, out_channels=1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.loss_func = nn.MSELoss(reduction='sum')\n",
    "        \n",
    "    def forward(self, in_data):\n",
    "        img_features = self.encoder(in_data)\n",
    "        logits = self.decoder(img_features)\n",
    "        return logits\n",
    "\n",
    "    def loss(self, logits, in_data):\n",
    "        return self.loss_func(logits, in_data) / logits.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactored runner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, loaders, optimizer, writer, num_epoch=10, device='cpu'):\n",
    "    def run_epoch(mode):\n",
    "        epoch_loss = 0.0\n",
    "        for i, batch in enumerate(loaders[mode], 0):\n",
    "            in_data, labels = batch\n",
    "            in_data, labels = in_data.to(device), labels.to(device)\n",
    "\n",
    "            if mode == 'train':\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            logits = model(in_data)\n",
    "            batch_loss = model.loss(logits, in_data)\n",
    "\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            if mode == 'train':\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # sum of all batchs / num of batches\n",
    "        epoch_loss /= i + 1 \n",
    "        \n",
    "        print('epoch %d %s loss %.4f' % (epoch, mode, epoch_loss))\n",
    "        # log to tensorboard\n",
    "        if not (writer is None):\n",
    "            writer.add_scalars('%s_loss' % model.__class__.__name__,\n",
    "                         tag_scalar_dict={mode: epoch_loss}, \n",
    "                         global_step=epoch)\n",
    "            # log image every 5 epoch\n",
    "            if mode == 'eval':\n",
    "                img_grid = make_grid(in_data.to('cpu'))\n",
    "                writer.add_image('%s/eval_input' % model.__class__.__name__, img_grid, epoch)\n",
    "                img_grid = make_grid(logits.to('cpu'))\n",
    "                writer.add_image('%s/eval_output' % model.__class__.__name__, img_grid, epoch)\n",
    "    for epoch in range(num_epoch):\n",
    "        run_epoch('train')\n",
    "        run_epoch('eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout Validation for choosing hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam_0.001\n",
      "epoch 0 train loss 59.8725\n",
      "epoch 0 eval loss 36.5190\n",
      "epoch 1 train loss 32.9882\n",
      "epoch 1 eval loss 30.6163\n",
      "epoch 2 train loss 29.1995\n",
      "epoch 2 eval loss 28.0643\n",
      "epoch 3 train loss 27.2804\n",
      "epoch 3 eval loss 26.5362\n",
      "epoch 4 train loss 26.0952\n",
      "epoch 4 eval loss 25.5648\n",
      "epoch 5 train loss 25.3106\n",
      "epoch 5 eval loss 25.0196\n",
      "epoch 6 train loss 24.7278\n",
      "epoch 6 eval loss 24.4132\n",
      "epoch 7 train loss 24.2700\n",
      "epoch 7 eval loss 24.0777\n",
      "epoch 8 train loss 23.8909\n",
      "epoch 8 eval loss 23.9027\n",
      "epoch 9 train loss 23.5714\n",
      "epoch 9 eval loss 23.6148\n",
      "sgd_0.1\n",
      "epoch 0 train loss 111.2021\n",
      "epoch 0 eval loss 110.6310\n",
      "epoch 1 train loss 111.1424\n",
      "epoch 1 eval loss 110.6310\n",
      "epoch 2 train loss 111.1424\n",
      "epoch 2 eval loss 110.6310\n",
      "epoch 3 train loss 111.1424\n",
      "epoch 3 eval loss 110.6310\n",
      "epoch 4 train loss 111.1424\n",
      "epoch 4 eval loss 110.6310\n",
      "epoch 5 train loss 111.1424\n",
      "epoch 5 eval loss 110.6310\n",
      "epoch 6 train loss 111.1424\n",
      "epoch 6 eval loss 110.6310\n",
      "epoch 7 train loss 111.1424\n",
      "epoch 7 eval loss 110.6310\n",
      "epoch 8 train loss 111.1424\n",
      "epoch 8 eval loss 110.6310\n",
      "epoch 9 train loss 111.1424\n",
      "epoch 9 eval loss 110.6310\n",
      "sgd_0.01\n",
      "epoch 0 train loss 68.7171\n",
      "epoch 0 eval loss 63.1769\n",
      "epoch 1 train loss 40.9517\n",
      "epoch 1 eval loss 32.1993\n",
      "epoch 2 train loss 30.8053\n",
      "epoch 2 eval loss 31.1221\n",
      "epoch 3 train loss 27.9335\n",
      "epoch 3 eval loss 26.5084\n",
      "epoch 4 train loss 25.5949\n",
      "epoch 4 eval loss 25.5866\n",
      "epoch 5 train loss 23.8530\n",
      "epoch 5 eval loss 23.3559\n",
      "epoch 6 train loss 23.2399\n",
      "epoch 6 eval loss 23.3425\n",
      "epoch 7 train loss 22.8340\n",
      "epoch 7 eval loss 22.1850\n",
      "epoch 8 train loss 22.5659\n",
      "epoch 8 eval loss 21.7025\n",
      "epoch 9 train loss 22.2904\n",
      "epoch 9 eval loss 21.7008\n"
     ]
    }
   ],
   "source": [
    "for optim_conf in [\n",
    "    {'optim':'adam', 'lr':0.001},\n",
    "    {'optim':'sgd', 'lr':0.1},\n",
    "    {'optim':'sgd', 'lr':0.01}\n",
    "]:\n",
    "    model = CaeFromPretrained()\n",
    "    if optim_conf['optim'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=optim_conf['lr'])\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=optim_conf['lr'])\n",
    "    conf_str = optim_conf['optim']+'_'+str(optim_conf['lr'])\n",
    "    print(conf_str)\n",
    "    run(\n",
    "        model=model,\n",
    "        loaders={\n",
    "            'train': torch.utils.data.DataLoader(holdout_train_data, batch_size=32, shuffle=True),\n",
    "            'eval': torch.utils.data.DataLoader(holdout_eval_data, batch_size=32, shuffle=True)\n",
    "        },\n",
    "        optimizer=optimizer, \n",
    "        writer=SummaryWriter('./logs/cae/%s' % (conf_str)), \n",
    "        num_epoch=10, \n",
    "        device='cpu'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training final model\n",
    "Hyper-parameters:\n",
    "Optimization: SGD, learning rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final\n",
      "epoch 0 train loss 56.8960\n",
      "epoch 0 eval loss 37.1465\n",
      "epoch 1 train loss 30.5123\n",
      "epoch 1 eval loss 28.4783\n",
      "epoch 2 train loss 25.9272\n",
      "epoch 2 eval loss 25.6136\n",
      "epoch 3 train loss 24.1849\n",
      "epoch 3 eval loss 22.5642\n",
      "epoch 4 train loss 23.0729\n",
      "epoch 4 eval loss 22.3533\n",
      "epoch 5 train loss 22.2945\n",
      "epoch 5 eval loss 21.4649\n",
      "epoch 6 train loss 21.7284\n",
      "epoch 6 eval loss 21.8093\n",
      "epoch 7 train loss 21.2337\n",
      "epoch 7 eval loss 21.3707\n",
      "epoch 8 train loss 20.8897\n",
      "epoch 8 eval loss 21.1576\n",
      "epoch 9 train loss 20.5797\n",
      "epoch 9 eval loss 20.4619\n",
      "epoch 10 train loss 20.3135\n",
      "epoch 10 eval loss 19.9867\n",
      "epoch 11 train loss 20.1514\n",
      "epoch 11 eval loss 19.8553\n",
      "epoch 12 train loss 19.9933\n",
      "epoch 12 eval loss 20.2345\n",
      "epoch 13 train loss 19.9044\n",
      "epoch 13 eval loss 19.9957\n",
      "epoch 14 train loss 19.8460\n",
      "epoch 14 eval loss 19.6911\n",
      "epoch 15 train loss 19.7230\n",
      "epoch 15 eval loss 19.4345\n",
      "epoch 16 train loss 19.6655\n",
      "epoch 16 eval loss 19.3933\n",
      "epoch 17 train loss 19.5704\n",
      "epoch 17 eval loss 19.5384\n",
      "epoch 18 train loss 19.5183\n",
      "epoch 18 eval loss 19.3235\n",
      "epoch 19 train loss 19.4565\n",
      "epoch 19 eval loss 19.7622\n"
     ]
    }
   ],
   "source": [
    "model = CaeFromPretrained()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "conf_str = 'final'\n",
    "print(conf_str)\n",
    "run(\n",
    "    model=model,\n",
    "    loaders={\n",
    "        'train': torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True),\n",
    "        'eval': torch.utils.data.DataLoader(eval_data, batch_size=32, shuffle=True)\n",
    "    },\n",
    "    optimizer=optimizer, \n",
    "    writer=SummaryWriter('./logs/cae/%s' % (conf_str)), \n",
    "    num_epoch=20, \n",
    "    device='cpu'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
