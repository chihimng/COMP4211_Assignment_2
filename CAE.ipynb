{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAE from pretrained encoder\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "from tensorboardX import SummaryWriter\n",
    "from pa2_sample_code import get_datasets\n",
    "\n",
    "train_data, eval_data = get_datasets()\n",
    "\n",
    "# split train set into holdout_train and holdout_eval sets\n",
    "holdout_train_len = int(len(train_data) * 0.8)\n",
    "holdout_eval_len = len(train_data) - holdout_train_len\n",
    "holdout_train_data, holdout_eval_data = torch.utils.data.random_split(train_data, [holdout_train_len, holdout_eval_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaeFromPretrained(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CaeFromPretrained, self).__init__()\n",
    "        \n",
    "        self.encoder = torch.load('pretrained_encoder.pt')['model']\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=8, kernel_size=3, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=4, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=4, out_channels=1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.loss_func = nn.MSELoss(reduction='sum')\n",
    "        \n",
    "    def forward(self, in_data):\n",
    "        img_features = self.encoder(in_data)\n",
    "        logits = self.decoder(img_features)\n",
    "        return logits\n",
    "\n",
    "    def loss(self, logits, in_data):\n",
    "        return self.loss_func(logits, in_data) / logits.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactored runner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, loaders, optimizer, writer, num_epoch=10, device='cpu'):\n",
    "    def run_epoch(mode):\n",
    "        epoch_loss = 0.0\n",
    "        for i, batch in enumerate(loaders[mode], 0):\n",
    "            in_data, labels = batch\n",
    "            in_data, labels = in_data.to(device), labels.to(device)\n",
    "\n",
    "            if mode == 'train':\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            logits = model(in_data)\n",
    "            batch_loss = model.loss(logits, in_data)\n",
    "\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            if mode == 'train':\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # sum of all batchs / num of batches\n",
    "        epoch_loss /= i + 1 \n",
    "        \n",
    "        print('epoch %d %s loss %.4f' % (epoch, mode, epoch_loss))\n",
    "        # log to tensorboard\n",
    "        if not (writer is None):\n",
    "            writer.add_scalars('%s_loss' % model.__class__.__name__,\n",
    "                         tag_scalar_dict={mode: epoch_loss}, \n",
    "                         global_step=epoch)\n",
    "            # log image\n",
    "            if mode == 'eval':\n",
    "                if len(in_data.size()) == 2: # reshape if flattened\n",
    "                    in_data = in_data.view(-1, 1, 28, 28)\n",
    "                if len(logits.size()) == 2: # reshape if flattened\n",
    "                    logits = logits.view(-1, 1, 28, 28)\n",
    "                img_grid = make_grid(in_data.to('cpu'))\n",
    "                writer.add_image('%s/eval_input' % model.__class__.__name__, img_grid, epoch)\n",
    "                img_grid = make_grid(logits.to('cpu'))\n",
    "                writer.add_image('%s/eval_output' % model.__class__.__name__, img_grid, epoch)\n",
    "    for epoch in range(num_epoch):\n",
    "        run_epoch('train')\n",
    "        run_epoch('eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout Validation for choosing hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam_0.001\n",
      "epoch 0 train loss 57.0275\n",
      "epoch 0 eval loss 37.5400\n",
      "epoch 1 train loss 34.3430\n",
      "epoch 1 eval loss 32.0027\n",
      "epoch 2 train loss 30.9334\n",
      "epoch 2 eval loss 29.8890\n",
      "epoch 3 train loss 29.1871\n",
      "epoch 3 eval loss 28.4027\n",
      "epoch 4 train loss 28.1395\n",
      "epoch 4 eval loss 27.5926\n",
      "epoch 5 train loss 27.4126\n",
      "epoch 5 eval loss 26.9978\n",
      "epoch 6 train loss 26.8849\n",
      "epoch 6 eval loss 26.5602\n",
      "epoch 7 train loss 26.4478\n",
      "epoch 7 eval loss 26.2031\n",
      "epoch 8 train loss 25.8842\n",
      "epoch 8 eval loss 25.4438\n",
      "epoch 9 train loss 25.0411\n",
      "epoch 9 eval loss 23.9046\n",
      "sgd_0.1\n",
      "epoch 0 train loss 111.0752\n",
      "epoch 0 eval loss 111.1485\n",
      "epoch 1 train loss 111.0128\n",
      "epoch 1 eval loss 111.1485\n",
      "epoch 2 train loss 111.0127\n",
      "epoch 2 eval loss 111.1485\n",
      "epoch 3 train loss 111.0127\n",
      "epoch 3 eval loss 111.1484\n",
      "epoch 4 train loss 111.0127\n",
      "epoch 4 eval loss 111.1484\n",
      "epoch 5 train loss 111.0127\n",
      "epoch 5 eval loss 111.1484\n",
      "epoch 6 train loss 111.0127\n",
      "epoch 6 eval loss 111.1484\n",
      "epoch 7 train loss 111.0126\n",
      "epoch 7 eval loss 111.1483\n",
      "epoch 8 train loss 111.0125\n",
      "epoch 8 eval loss 111.1482\n",
      "epoch 9 train loss 111.0119\n",
      "epoch 9 eval loss 111.1411\n",
      "sgd_0.01\n",
      "epoch 0 train loss 71.9676\n",
      "epoch 0 eval loss 70.1092\n",
      "epoch 1 train loss 69.9735\n",
      "epoch 1 eval loss 69.7064\n",
      "epoch 2 train loss 65.7431\n",
      "epoch 2 eval loss 56.0864\n",
      "epoch 3 train loss 41.7997\n",
      "epoch 3 eval loss 31.5280\n",
      "epoch 4 train loss 31.0801\n",
      "epoch 4 eval loss 29.3443\n",
      "epoch 5 train loss 28.3601\n",
      "epoch 5 eval loss 30.5444\n",
      "epoch 6 train loss 26.4067\n",
      "epoch 6 eval loss 26.9154\n",
      "epoch 7 train loss 25.1453\n",
      "epoch 7 eval loss 23.4926\n",
      "epoch 8 train loss 24.5790\n",
      "epoch 8 eval loss 24.0725\n",
      "epoch 9 train loss 24.0931\n",
      "epoch 9 eval loss 22.6747\n"
     ]
    }
   ],
   "source": [
    "for optim_conf in [\n",
    "    {'optim':'adam', 'lr':0.001},\n",
    "    {'optim':'sgd', 'lr':0.1},\n",
    "    {'optim':'sgd', 'lr':0.01}\n",
    "]:\n",
    "    model = CaeFromPretrained()\n",
    "    if optim_conf['optim'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=optim_conf['lr'])\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=optim_conf['lr'])\n",
    "    conf_str = optim_conf['optim']+'_'+str(optim_conf['lr'])\n",
    "    print(conf_str)\n",
    "    run(\n",
    "        model=model,\n",
    "        loaders={\n",
    "            'train': torch.utils.data.DataLoader(holdout_train_data, batch_size=32, shuffle=True),\n",
    "            'eval': torch.utils.data.DataLoader(holdout_eval_data, batch_size=32, shuffle=True)\n",
    "        },\n",
    "        optimizer=optimizer, \n",
    "        writer=SummaryWriter('./logs/cae/%s' % (conf_str)), \n",
    "        num_epoch=10, \n",
    "        device='cpu'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training final model\n",
    "Hyper-parameters:\n",
    "Optimization: SGD, learning rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final\n",
      "epoch 0 train loss 50.6091\n",
      "epoch 0 eval loss 34.6583\n",
      "epoch 1 train loss 32.1074\n",
      "epoch 1 eval loss 30.2909\n",
      "epoch 2 train loss 29.0967\n",
      "epoch 2 eval loss 28.4016\n",
      "epoch 3 train loss 27.7402\n",
      "epoch 3 eval loss 27.4155\n",
      "epoch 4 train loss 26.8294\n",
      "epoch 4 eval loss 26.3066\n",
      "epoch 5 train loss 25.0460\n",
      "epoch 5 eval loss 23.9013\n",
      "epoch 6 train loss 23.5204\n",
      "epoch 6 eval loss 23.2212\n",
      "epoch 7 train loss 23.0278\n",
      "epoch 7 eval loss 22.9713\n",
      "epoch 8 train loss 22.6826\n",
      "epoch 8 eval loss 22.7582\n",
      "epoch 9 train loss 22.4043\n",
      "epoch 9 eval loss 22.5769\n",
      "epoch 10 train loss 22.1619\n",
      "epoch 10 eval loss 22.1497\n",
      "epoch 11 train loss 21.9616\n",
      "epoch 11 eval loss 22.0626\n",
      "epoch 12 train loss 21.7847\n",
      "epoch 12 eval loss 21.8373\n",
      "epoch 13 train loss 21.6437\n",
      "epoch 13 eval loss 21.6873\n",
      "epoch 14 train loss 21.5191\n",
      "epoch 14 eval loss 21.6005\n"
     ]
    }
   ],
   "source": [
    "model = CaeFromPretrained()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "conf_str = 'final'\n",
    "print(conf_str)\n",
    "run(\n",
    "    model=model,\n",
    "    loaders={\n",
    "        'train': torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True),\n",
    "        'eval': torch.utils.data.DataLoader(eval_data, batch_size=32, shuffle=True)\n",
    "    },\n",
    "    optimizer=optimizer, \n",
    "    writer=SummaryWriter('./logs/cae/%s' % (conf_str)), \n",
    "    num_epoch=15, \n",
    "    device='cpu'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
